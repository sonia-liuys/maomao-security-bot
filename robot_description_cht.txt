### 這個檔案是給AI讀的

這台機器人結合了AI影像辨識、感測器與多馬達控制，具備三種主要模式：**手動模式、巡邏模式、監視模式**，能靈活應用於安全巡邏與互動展示。以下為各模式功能、硬體架構與AI設計：

---

### 1. 手動模式
- 使用者可透過胸部平板或遠端控制，讓機器人執行八種移動動作（前進、後退、持續前進、持續後退、停止、左轉90度、右轉90度、正方形行走）。
- 機器人眼睛顯示綠色，會自然眨眼並搖晃手臂，展現生動互動。

### 2. 巡邏模式
- 機器人每30秒自動沿著正方形路徑巡邏，眼睛為綠色。
- 巡邏時若偵測到人臉，會先判斷是否為認識的人：
  - 若不是認識的人，機器人會停下來，眼睛變紅，胸口平板顯示「請離開」。
- 偵測到人臉時，眼睛會跟隨對方移動。
- 結合超音波感測，遇到障礙時會自動停下來。

### 3. 監視模式
- 可透過平板進行遠端控制，並可隨時切換到其他模式。
- 偵測到壞人後，點擊平板上的恢復按鈕可讓機器人恢復正常狀態。
- 當偵測到人臉時，會先判斷是否為認識的人：
  - 如果是認識的人，平板顯示「哈囉！歡迎回家」。
  - 如果不是，眼睛轉為黃色，舉起右手，並啟動5秒倒數偵測（平板顯示倒數）。
    - 若5秒後人已離開，眼睛恢復綠色，右手放下。
    - 若5秒後人還在，眼睛變紅、雙手舉起、打開右手上的雷射，並將陌生人臉顯示在平板上，同時顯示「我已經報警了」。
- 當偵測到學生證後，機器人會回到初始狀態，暫停人臉偵測60秒後再繼續監視。

---

### 4. 硬體架構
- **胸部平板**  
  顯示操作介面、即時影像、警報訊息，並提供「恢復按鈕」與學生證感應功能。
  
- **樹莓派5**  
  - 連接攝影機執行AI影像辨識
  - 控制9個伺服馬達：
    | 伺服編號 | 控制部位       |
    |----------|----------------|
    | 1        | 眼球水平運動   |
    | 2        | 眼球垂直運動   |
    | 3-6      | 雙眼皮開合     |
    | 7        | 頸部轉動       |
    | 8-9      | 左右手臂動作   |
  
- **Arduino**  
  - 透過序列埠與樹莓派通訊
  - 驅動麥克納姆輪（實現八種移動模式）
  - 控制雷射指示器與超音波感測器

---

### 5. AI辨識系統
- **技術工具**：使用Google Teachable Machine訓練模型，部署於樹莓派5
- **辨識類別**：
  1. Sonia（特定人臉）
  2. Matthew（特定人臉）
  3. Sonia's ID badges（學生證）
  4. Matthew's ID badges（學生證）
- **處理邏輯**：
  - 若辨識可信度低於閾值，視為未識別人員
  - 即時追蹤人臉並控制眼球馬達（1號與2號）跟隨移動

---

### 各伺服馬達控制部位

- **1號馬達**：眼球水平運動（控制雙眼左右移動）  
- **2號馬達**：眼球垂直運動（控制雙眼上下移動）  
- **3號馬達**：左下眼皮開合  
- **4號馬達**：右下眼皮開合  
- **5號馬達**：左上眼皮開合  
- **6號馬達**：右上眼皮開合  
- **7號馬達**：頸部運動（控制頭部轉動或俯仰）  
- **8號馬達**：右手臂動作（舉起、放下或擺動右手臂）  
- **9號馬達**：左手臂動作（舉起、放下或擺動左手臂）  


